import os
import requests  # å¤–éƒ¨APIå–å¾—ç”¨ã«è¿½åŠ 
from flask import Flask, jsonify, request, send_from_directory
from flask_cors import CORS
import google.generativeai as genai
import stations
import math
from datetime import datetime

app = Flask(__name__, static_folder="../frontend/build", static_url_path="/")
CORS(app)

# --- è¨­å®š ---
ODPT_API_KEY = os.environ.get("ODPT_API_KEY")
genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
model = genai.GenerativeModel("models/gemini-flash-latest")

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®IDã¨ODPTã®æ­£å¼ãªè·¯ç·šè­˜åˆ¥å­(URN)ã®ç´ä»˜ã‘
LINE_MAP = {
    "yamanote": "odpt.Line:JR-East.Yamanote",
    "chuo": "odpt.Line:JR-East.ChuoRapid",
    "saikyo": "odpt.Line:JR-East.Saikyo",
    "shonan": "odpt.Line:JR-East.ShonanShinjuku",
    "denentoshi": "odpt.Line:Tokyu.DenEnToshi",
    "hanzomon": "odpt.Line:TokyoMetro.Hanzomon",
}


# GPSåº§æ¨™é–“ã®è·é›¢ã‚’è¨ˆç®—ï¼ˆãƒãƒãƒ¼ã‚µã‚¤ãƒ³å…¬å¼ï¼‰
def calculate_distance_km(lat1, lon1, lat2, lon2):
    """ç·¯åº¦çµŒåº¦ã‹ã‚‰ã‚­ãƒ­ãƒ¡ãƒ¼ãƒˆãƒ«å˜ä½ã®è·é›¢ã‚’è¨ˆç®—"""
    R = 6371  # åœ°çƒåŠå¾„ï¼ˆkmï¼‰
    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = (
        math.sin(dlat / 2) ** 2
        + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2
    )
    c = 2 * math.asin(math.sqrt(a))
    return R * c


def estimate_travel_minutes(distance_km):
    """è·é›¢ã‹ã‚‰ãŠãŠã‚ˆãã®æ‰€è¦æ™‚é–“ï¼ˆåˆ†ï¼‰ã‚’æ¨å®š"""
    # æ±äº¬ã®å¹³å‡çš„ãªå…¬å…±äº¤é€šé€Ÿåº¦ã¯æ™‚é€Ÿ20kmç¨‹åº¦ã¨ä»®å®š
    minutes = int((distance_km / 20) * 60 + 5)
    return max(1, minutes)


def find_nearest_station(user_lat, user_lng, exclude_station_name=None):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¾åœ¨åœ°ã‹ã‚‰æœ€å¯„ã‚Šé§…ã‚’æ¢ç´¢"""
    min_distance = float("inf")
    nearest_station = None

    for station in stations.STATIONS:
        if exclude_station_name and station["name"] == exclude_station_name:
            continue

        distance = calculate_distance_km(
            float(user_lat), float(user_lng), station["lat"], station["lng"]
        )

        if distance < min_distance:
            min_distance = distance
            nearest_station = station

    return nearest_station


# æ™‚é–“å¸¯ã”ã¨ã®æ··é›‘åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ0-10æ®µéšã€10ãŒæœ€ã‚‚æ··é›‘ï¼‰
CONGESTION_PATTERN = {
    (7, 9): 8,  # æœãƒ©ãƒƒã‚·ãƒ¥: éå¸¸ã«æ··é›‘
    (9, 11): 6,  # æœã‹ã‚‰æ˜¼: ã‚„ã‚„æ··é›‘
    (11, 14): 3,  # æ˜¼é–“: ç©ºã„ã¦ã„ã‚‹
    (14, 16): 4,  # åˆå¾Œ: å°‘ã—æ··é›‘
    (16, 19): 7,  # å¤•æ–¹ãƒ©ãƒƒã‚·ãƒ¥: æ··é›‘
    (19, 21): 5,  # å¤œé–“: ã‚„ã‚„æ··é›‘
}


def get_congestion_level():
    """ç¾åœ¨ã®æ™‚é–“å¸¯ã‹ã‚‰æ··é›‘åº¦ã‚’å–å¾—"""
    now = datetime.now()
    hour = now.hour

    for (start, end), level in CONGESTION_PATTERN.items():
        if start <= hour < end:
            return level, hour

    # ä¸Šè¨˜ä»¥å¤–ã®æ™‚é–“ï¼ˆ21-7æ™‚ï¼‰ã¯ç©ºã„ã¦ã„ã‚‹
    return 2, hour


def get_congestion_info():
    """ç¾åœ¨æ™‚åˆ»ã®æ··é›‘åº¦ã¨èª¬æ˜æ–‡ã‚’è¨ˆç®—"""
    level, hour = get_congestion_level()

    # æ··é›‘åº¦ã«åŸºã¥ãèª¬æ˜æ–‡
    if level >= 8:
        description = "éå¸¸ã«æ··é›‘ã—ã¦ã„ã‚‹æ™‚é–“å¸¯ã§ã™"
        emoji = "ğŸ”´"
    elif level >= 6:
        description = "æ··é›‘ã—ã¦ã„ã‚‹æ™‚é–“å¸¯ã§ã™"
        emoji = "ğŸŸ "
    elif level >= 4:
        description = "ã‚„ã‚„æ··é›‘ã—ã¦ã„ã‚‹æ™‚é–“å¸¯ã§ã™"
        emoji = "ğŸŸ¡"
    else:
        description = "æ¯”è¼ƒçš„ç©ºã„ã¦ã„ã‚‹æ™‚é–“å¸¯ã§ã™"
        emoji = "ğŸŸ¢"

    return {"level": level, "description": description, "emoji": emoji, "hour": hour}


def serve():
    return send_from_directory(app.static_folder, "index.html")


@app.route("/api/lines")
def lines():
    return jsonify(stations.ALL_LINES)


@app.route("/api/stations")
def get_stations():
    raw_line_id = request.args.get("line_id")
    if not raw_line_id:
        return jsonify(stations.STATIONS)

    line_id = raw_line_id.strip().replace('"', "").replace("'", "").lower()

    if line_id in LINE_MAP and ODPT_API_KEY:
        url = "https://api.odpt.org/api/v4/odpt:Station"
        params = {"odpt:line": LINE_MAP[line_id], "acl:consumerKey": ODPT_API_KEY}

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ç°¡æ˜“ãƒªãƒˆãƒ©ã‚¤è¨­å®š
        timeout_seconds = 10
        max_attempts = 2
        for attempt in range(1, max_attempts + 1):
            try:
                response = requests.get(url, params=params, timeout=timeout_seconds)
                response.raise_for_status()
                api_data = response.json()

                if api_data:
                    formatted_stations = []
                    for s in api_data:
                        formatted_stations.append(
                            {
                                "id": s.get("owl:sameAs"),
                                "name": s.get("dc:title", "ä¸æ˜ãªé§…"),
                                "line_id": line_id,
                                "lat": s.get("geo:lat"),
                                "lng": s.get("geo:long"),
                            }
                        )
                    formatted_stations.sort(key=lambda x: x["name"])
                    return jsonify(formatted_stations)

                # ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹ãªã‚‰ãƒªãƒˆãƒ©ã‚¤ã®å¯¾è±¡ã«ã™ã‚‹
                if attempt < max_attempts:
                    continue
                break

            except requests.RequestException as e:
                print(f"âš ï¸ ODPT request attempt {attempt} for {line_id} failed: {e}")
                if attempt < max_attempts:
                    continue
                # æœ€çµ‚çš„ã«å¤±æ•—ã—ãŸã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                break

    return jsonify(stations.get_stations_by_line(line_id))


@app.route("/api/gpt-prediction", methods=["POST"])
def gpt_prediction():
    data = request.json
    lat = data.get("lat")
    lng = data.get("lng")
    station_name = data.get("station_name", "ç›®çš„åœ°")
    station_lat = data.get("station_lat")
    station_lng = data.get("station_lng")

    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼šå—ã‘å–ã£ãŸãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’å‡ºåŠ›
    print(
        f"[GPT Prediction] User Location: ({lat}, {lng}), Destination: {station_name} ({station_lat}, {station_lng})"
    )

    # è·é›¢ã¨æ‰€è¦æ™‚é–“ã‚’è¨ˆç®—
    distance_km = calculate_distance_km(
        float(lat), float(lng), float(station_lat), float(station_lng)
    )
    estimated_minutes = estimate_travel_minutes(distance_km)

    # ç¾åœ¨åœ°ã‹ã‚‰æœ€å¯„ã‚Šé§…ã‚’æ¤œç´¢
    nearest_station = find_nearest_station(lat, lng, exclude_station_name=station_name)
    nearest_station_name = nearest_station["name"] if nearest_station else "æœ€å¯„ã‚Šé§…"

    # æ··é›‘åº¦æƒ…å ±ã‚’å–å¾—
    congestion_info = get_congestion_info()

    print(f"[Distance] {distance_km:.2f}km, Estimated: {estimated_minutes}min")
    print(f"[Nearest Station] {nearest_station_name}")
    print(
        f"[Congestion] Level {congestion_info['level']}: {congestion_info['description']}"
    )

    prompt = f"""ã‚ãªãŸã¯IBSï¼ˆéæ•æ€§è…¸ç—‡å€™ç¾¤ï¼‰ã§è‹¦ã—ã‚€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ•‘ã†ã€æœ€é«˜å³°ã®é§…æ§‹å†…ã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥ã§ã™ã€‚

ã€é‡è¦ãªæƒ…å ±ã€‘
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¾åœ¨åœ°ï¼ˆGPSï¼‰: ç·¯åº¦{lat}, çµŒåº¦{lng}
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€ã‚‚è¿‘ã„é§…: {nearest_station_name}
ç›®çš„é§…ã€Œ{station_name}ã€ï¼ˆGPSï¼‰: ç·¯åº¦{station_lat}, çµŒåº¦{station_lng}
è¨ˆç®—æ¸ˆã¿ã®ç›´ç·šè·é›¢: {distance_km:.2f}km
æ¨å®šæ‰€è¦æ™‚é–“: {estimated_minutes}åˆ†
ç¾åœ¨ã®æ··é›‘åº¦: {congestion_info["emoji"]} ãƒ¬ãƒ™ãƒ«{congestion_info["level"]}/10 - {congestion_info["description"]}

ã€æŒ‡ç¤ºã€‘
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œ{nearest_station_name}ã€ã«ã„ã¾ã™
2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œ{station_name}ã€ã¸ç§»å‹•ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
3. ä¸Šè¨˜ã®æ¨å®šæ‰€è¦æ™‚é–“{estimated_minutes}åˆ†ã‚’åŸºæº–ã«å›ç­”ã—ã¦ãã ã•ã„
4. ã‚ˆã‚ŠçŸ­ã„ãƒ«ãƒ¼ãƒˆã‚’è¦‹ã¤ã‘ãŸå ´åˆã®ã¿ã€ãã‚Œã‚ˆã‚Šå°‘ãªã„æ™‚é–“ã‚’æç¤ºã§ãã¾ã™
5. {station_name}é§…æ§‹å†…ã®ãƒˆã‚¤ãƒ¬ä½ç½®ã‚‚æç¤ºã—ã¦ãã ã•ã„
6. æ··é›‘çŠ¶æ³ãŒæ‚ªã„å ´åˆã¯ã€ãƒ«ãƒ¼ãƒˆæç¤ºã®éš›ã«ã€ŒäººãŒå¤šã„ã®ã§æ€¥ã„ã§ç§»å‹•ã—ã¦ãã ã•ã„ã€ãªã©ã®æ³¨æ„ã‚’åŠ ãˆã¦ãã ã•ã„
7. çµ¶å¯¾ã«ã€ã€Œ{station_name}ã€ã®åˆ¥ã®é§…ã‹ã‚‰ã®çµŒè·¯ã‚’æç¤ºã—ãªã„ã§ãã ã•ã„

ã€å›ç­”å½¢å¼ã€‘å¿…ãšJSONå½¢å¼ã®ã¿ã§è¿”ã—ã¦ãã ã•ã„
{{
  "minutes": {estimated_minutes},
  "steps": ["ã‚¹ãƒ†ãƒƒãƒ—1", "ã‚¹ãƒ†ãƒƒãƒ—2", "ã‚¹ãƒ†ãƒƒãƒ—3"],
  "toilet_info": "ãƒˆã‚¤ãƒ¬ã®å…·ä½“çš„ãªä½ç½®",
  "congestion_emoji": "{congestion_info["emoji"]}",
  "congestion_level": {congestion_info["level"]},
  "message": "15æ–‡å­—ä»¥å†…ã®åŠ±ã¾ã—"
}}
"""

    try:
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                response_mime_type="application/json"
            ),
        )
        return response.text
    except Exception as e:
        print(f"Gemini Error: {e}")
        return jsonify(
            {
                "minutes": estimated_minutes,
                "steps": [f"{station_name}ã¸ç›´è¡Œã—ã¦ãã ã•ã„"],
                "toilet_info": "é§…åˆ°ç€å¾Œã€æ¡ˆå†…å›³ã‚’è¦‹ã¦æœ€ã‚‚è¿‘ã„ãƒˆã‚¤ãƒ¬ã¸ï¼",
                "message": "è«¦ã‚ã‚‹ãªï¼ãŠå°»ã‚’ç· ã‚ã‚ï¼",
            }
        )


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
